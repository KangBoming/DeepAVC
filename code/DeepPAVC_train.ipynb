{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from utils.Func import extract_cp_feature\n",
    "from dgl.data.utils import load_graphs\n",
    "from utils.PAVC_dataset import PAVC_Dataset_Train\n",
    "from utils.collator import Collator_PAVC_Train\n",
    "from utils.PAVC_trainer import PAVC_Trainer\n",
    "from utils.scheduler import PolynomialDecayLR\n",
    "from torch.optim import Adam\n",
    "from torch.nn import  BCEWithLogitsLoss\n",
    "from utils.model.KPGT import *\n",
    "from utils.featurizer import Vocab, N_ATOM_TYPES, N_BOND_TYPES,VIRTUAL_ATOM_FEATURE_PLACEHOLDER, VIRTUAL_BOND_FEATURE_PLACEHOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'config':'base',\n",
    "    'd_fps': 512,\n",
    "    'd_mds': 200,\n",
    "    'dropout':0,\n",
    "    'weight_decay':1e-6,\n",
    "    'n_tasks':1,\n",
    "    'lr': 3e-5,\n",
    "    'model_path':'/home2/kangboming/kangboming/workspace2/AVC_paper/github/pretrained_model/KPGT/KPGT.pth',\n",
    "    'cp_feature_dir': '/home2/kangboming/kangboming/workspace2/AVC_paper/github/data/DeepPAVC/cp_feature',\n",
    "    'n_epochs':10, \n",
    "    'device':'cuda:3',\n",
    "    'random_seed': 42,\n",
    "    'batch_size':32,\n",
    "    'train_ratio': 0.8,\n",
    "    'val_ratio': 0.1,\n",
    "    'test_ratio':0.1,\n",
    "    'MLP_layer_num':2,\n",
    "    'MLP_hidden_dim':256}\n",
    "vocab = Vocab(N_ATOM_TYPES, N_BOND_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = pd.read_csv('/home2/kangboming/kangboming/workspace2/AVC_paper/github/data/DeepPAVC/DeepPAVC_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = alldata.sample(2000)['smiles'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract initial compound feature ( by RDkit)\n",
    "extract_cp_feature(smiles_list= smiles_list,\n",
    "                   output_dir= '/home2/kangboming/kangboming/workspace2/AVC_paper/github/data/DeepPAVC/cp_feature',\n",
    "                   num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 读取小分子特征\n",
    "graphs, label_dict = load_graphs(os.path.join(args['cp_feature_dir'], 'cp_graphs.pkl'))\n",
    "fps = torch.load(os.path.join(args['cp_feature_dir'], 'cp_fps.pt'))\n",
    "mds = torch.load(os.path.join(args['cp_feature_dir'], 'cp_mds.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(graphs) == len(fps) == len(mds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataset\n",
    "PAVC_dataset = PAVC_Dataset_Train(smiles_list = smiles_list,\n",
    "                             graphs = graphs,\n",
    "                             ecfps = fps,\n",
    "                             mds = mds,\n",
    "                             label_list= alldata['label'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data split\n",
    "train_ratio = args['train_ratio']\n",
    "val_ratio = args['val_ratio']\n",
    "dataset_size = len(PAVC_dataset)\n",
    "train_size = int(train_ratio * dataset_size) \n",
    "val_size = int(val_ratio * dataset_size)   \n",
    "test_size = dataset_size - train_size - val_size \n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset = random_split(PAVC_dataset, [train_size, val_size, test_size])\n",
    "print(f'Train size:{len(train_dataset)}\\nValidation size:{len(val_dataset)}\\nTest size:{len(test_dataset)}')\n",
    "\n",
    "### build dataloader \n",
    "config = config_dict[args['config']]\n",
    "collator = Collator_PAVC_Train(config['path_length'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=args['batch_size'], \n",
    "                          shuffle=True,  \n",
    "                          drop_last=False, \n",
    "                          collate_fn=collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args['batch_size'], \n",
    "                        shuffle=False,\n",
    "                          drop_last=False, \n",
    "                          collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args['batch_size'], \n",
    "                         shuffle=False,  \n",
    "                         drop_last=False, \n",
    "                         collate_fn=collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1516246/3243420758.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Model initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model = LiGhTPredictor(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0md_node_feats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd_node_feats'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0md_edge_feats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd_edge_feats'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0md_g_feats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd_g_feats'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "### Model initialization\n",
    "model = LiGhTPredictor(\n",
    "    d_node_feats=config['d_node_feats'],\n",
    "    d_edge_feats=config['d_edge_feats'],\n",
    "    d_g_feats=config['d_g_feats'],\n",
    "    d_fp_feats=args['d_fps'],\n",
    "    d_md_feats=args['d_mds'],\n",
    "    d_hpath_ratio=config['d_hpath_ratio'],\n",
    "    n_mol_layers=config['n_mol_layers'],\n",
    "    path_length=config['path_length'],\n",
    "    n_heads=config['n_heads'],\n",
    "    n_ffn_dense_layers=config['n_ffn_dense_layers'],\n",
    "    input_drop=0,\n",
    "    attn_drop=args['dropout'],\n",
    "    feat_drop=args['dropout'],\n",
    "    n_node_types=vocab.vocab_size).to(args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add classification head\n",
    "def get_predictor(d_input_feats, n_tasks, n_layers, predictor_drop, device, d_hidden_feats=None):\n",
    "    if n_layers == 1:\n",
    "        predictor = nn.Linear(d_input_feats, n_tasks)\n",
    "    else:\n",
    "        predictor = nn.ModuleList()\n",
    "        predictor.append(nn.Linear(d_input_feats, d_hidden_feats))\n",
    "        predictor.append(nn.Dropout(predictor_drop))\n",
    "        predictor.append(nn.GELU())\n",
    "        for _ in range(n_layers-2):\n",
    "            predictor.append(nn.Linear(d_hidden_feats, d_hidden_feats))\n",
    "            predictor.append(nn.Dropout(predictor_drop))\n",
    "            predictor.append(nn.GELU())\n",
    "        predictor.append(nn.Linear(d_hidden_feats, n_tasks))\n",
    "        predictor = nn.Sequential(*predictor)\n",
    "    predictor.apply(lambda module: init_params(module))\n",
    "    return predictor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load pretrained weights\n",
    "model.load_state_dict({k.replace('module.',''):v for k,v in torch.load(args['model_path'],map_location=args['device']).items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: forzen KPGT's parameters and only train MLP \n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unused block\n",
    "del model.md_predictor\n",
    "del model.fp_predictor\n",
    "del model.node_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add MLP for classification\n",
    "model.predictor = get_predictor(d_input_feats=config['d_g_feats']*3, \n",
    "                                n_tasks=args['n_tasks'], \n",
    "                                n_layers=args['MLP_layer_num'], \n",
    "                                predictor_drop=args['dropout'], \n",
    "                                device=args['device'], \n",
    "                                d_hidden_feats=args['MLP_hidden_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print trainable parameters size\n",
    "print(\"Model has {:.4f}M parameters that require gradient updates\".format(\n",
    "sum(x.numel() for x in model.parameters() if x.requires_grad) / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam( filter(lambda p: p.requires_grad, model.parameters()),lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "\n",
    "lr_scheduler = PolynomialDecayLR(optimizer, \n",
    "                                 warmup_updates=args['n_epochs']*(len(train_loader))//100, \n",
    "                                 tot_updates=args['n_epochs']* (len(train_loader)) , \n",
    "                                 lr=args['lr'], \n",
    "                                 end_lr=1e-6,\n",
    "                                 power=1)\n",
    "\n",
    "loss_fn = BCEWithLogitsLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DeepPAVC Trainer initialization\n",
    "trainer = PAVC_Trainer(args, \n",
    "                  optimizer, \n",
    "                  lr_scheduler, \n",
    "                  loss_fn,\n",
    "                 device=args['device'],\n",
    "                 model_name='DeepPAVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train DeepPAVC model\n",
    "performance_res_df = trainer.fit(model=model,\n",
    "                      train_loader=train_loader,\n",
    "                      val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KPGT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
