{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from utils.Func import extract_cp_feature\n",
    "from dgl.data.utils import load_graphs\n",
    "from utils.PAVC_dataset import PAVC_Dataset_Train\n",
    "from utils.collator import Collator_PAVC_Train\n",
    "from utils.PAVC_trainer import PAVC_Trainer\n",
    "from utils.scheduler import PolynomialDecayLR\n",
    "from torch.optim import Adam\n",
    "from torch.nn import  BCEWithLogitsLoss\n",
    "from utils.model.KPGT import *\n",
    "from utils.featurizer import Vocab, N_ATOM_TYPES, N_BOND_TYPES,VIRTUAL_ATOM_FEATURE_PLACEHOLDER, VIRTUAL_BOND_FEATURE_PLACEHOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'config':'base',\n",
    "    'd_fps': 512,\n",
    "    'd_mds': 200,\n",
    "    'dropout':0,\n",
    "    'weight_decay':1e-6,\n",
    "    'n_tasks':1,\n",
    "    'lr': 3e-5,\n",
    "    'model_path':'../pretrained_model/KPGT/KPGT.pth',\n",
    "    'cp_feature_dir': '../data/DeepPAVC/cp_feature',\n",
    "    'n_epochs':10, \n",
    "    'device':'cuda:0',\n",
    "    'random_seed': 42,\n",
    "    'batch_size':32,\n",
    "    'train_ratio': 0.8,\n",
    "    'val_ratio': 0.1,\n",
    "    'test_ratio':0.1,\n",
    "    'MLP_layer_num':2,\n",
    "    'MLP_hidden_dim':256}\n",
    "vocab = Vocab(N_ATOM_TYPES, N_BOND_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DeepPAVC dataset\n",
    "DeepPAVC_dataset = pd.read_csv('../data/DeepPAVC/DeepPAVC_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = DeepPAVC_dataset['smiles'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract initial compound feature (by RDkit)\n",
    "extract_cp_feature(smiles_list= smiles_list,\n",
    "                   output_dir= '../data/DeepPAVC/cp_feature',\n",
    "                   num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load molecular initial feature\n",
    "graphs, label_dict = load_graphs(os.path.join(args['cp_feature_dir'], 'cp_graphs.pkl'))\n",
    "fps = torch.load(os.path.join(args['cp_feature_dir'], 'cp_fps.pt'))\n",
    "mds = torch.load(os.path.join(args['cp_feature_dir'], 'cp_mds.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(graphs) == len(fps) == len(mds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataset\n",
    "PAVC_dataset = PAVC_Dataset_Train(smiles_list = smiles_list,\n",
    "                             graphs = graphs,\n",
    "                             ecfps = fps,\n",
    "                             mds = mds,\n",
    "                             label_list= DeepPAVC_dataset['label'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data split\n",
    "train_ratio = args['train_ratio']\n",
    "val_ratio = args['val_ratio']\n",
    "dataset_size = len(PAVC_dataset)\n",
    "train_size = int(train_ratio * dataset_size) \n",
    "val_size = int(val_ratio * dataset_size)   \n",
    "test_size = dataset_size - train_size - val_size \n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset = random_split(PAVC_dataset, [train_size, val_size, test_size])\n",
    "print(f'Train size:{len(train_dataset)}\\nValidation size:{len(val_dataset)}\\nTest size:{len(test_dataset)}')\n",
    "\n",
    "### build dataloader \n",
    "config = config_dict[args['config']]\n",
    "collator = Collator_PAVC_Train(config['path_length'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=args['batch_size'], \n",
    "                          shuffle=True,  \n",
    "                          drop_last=False, \n",
    "                          collate_fn=collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args['batch_size'], \n",
    "                        shuffle=False,\n",
    "                          drop_last=False, \n",
    "                          collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args['batch_size'], \n",
    "                         shuffle=False,  \n",
    "                         drop_last=False, \n",
    "                         collate_fn=collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  model initialization\n",
    "DeepPAVC = LiGhTPredictor(\n",
    "    d_node_feats=config['d_node_feats'],\n",
    "    d_edge_feats=config['d_edge_feats'],\n",
    "    d_g_feats=config['d_g_feats'],\n",
    "    d_fp_feats=args['d_fps'],\n",
    "    d_md_feats=args['d_mds'],\n",
    "    d_hpath_ratio=config['d_hpath_ratio'],\n",
    "    n_mol_layers=config['n_mol_layers'],\n",
    "    path_length=config['path_length'],\n",
    "    n_heads=config['n_heads'],\n",
    "    n_ffn_dense_layers=config['n_ffn_dense_layers'],\n",
    "    input_drop=0,\n",
    "    attn_drop=args['dropout'],\n",
    "    feat_drop=args['dropout'],\n",
    "    n_node_types=vocab.vocab_size).to(args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add classification head\n",
    "def get_predictor(d_input_feats, n_tasks, n_layers, predictor_drop, device, d_hidden_feats=None):\n",
    "    if n_layers == 1:\n",
    "        predictor = nn.Linear(d_input_feats, n_tasks)\n",
    "    else:\n",
    "        predictor = nn.ModuleList()\n",
    "        predictor.append(nn.Linear(d_input_feats, d_hidden_feats))\n",
    "        predictor.append(nn.Dropout(predictor_drop))\n",
    "        predictor.append(nn.GELU())\n",
    "        for _ in range(n_layers-2):\n",
    "            predictor.append(nn.Linear(d_hidden_feats, d_hidden_feats))\n",
    "            predictor.append(nn.Dropout(predictor_drop))\n",
    "            predictor.append(nn.GELU())\n",
    "        predictor.append(nn.Linear(d_hidden_feats, n_tasks))\n",
    "        predictor = nn.Sequential(*predictor)\n",
    "    predictor.apply(lambda module: init_params(module))\n",
    "    return predictor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load pretrained weights\n",
    "DeepPAVC.load_state_dict({k.replace('module.',''):v for k,v in torch.load(args['model_path'],map_location=args['device']).items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: forzen KPGT's parameters and only train MLP \n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unused block\n",
    "del DeepPAVC.md_predictor\n",
    "del DeepPAVC.fp_predictor\n",
    "del DeepPAVC.node_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add MLP for classification\n",
    "DeepPAVC.predictor = get_predictor(d_input_feats=config['d_g_feats']*3, \n",
    "                                n_tasks=args['n_tasks'], \n",
    "                                n_layers=args['MLP_layer_num'], \n",
    "                                predictor_drop=args['dropout'], \n",
    "                                device=args['device'], \n",
    "                                d_hidden_feats=args['MLP_hidden_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print trainable parameters size\n",
    "print(\"Model has {:.4f}M parameters that require gradient updates\".format(\n",
    "sum(x.numel() for x in DeepPAVC.parameters() if x.requires_grad) / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam( filter(lambda p: p.requires_grad, DeepPAVC.parameters()),lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "\n",
    "lr_scheduler = PolynomialDecayLR(optimizer, \n",
    "                                 warmup_updates=args['n_epochs']*(len(train_loader))//100, \n",
    "                                 tot_updates=args['n_epochs']* (len(train_loader)) , \n",
    "                                 lr=args['lr'], \n",
    "                                 end_lr=1e-6,\n",
    "                                 power=1)\n",
    "\n",
    "loss_fn = BCEWithLogitsLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DeepPAVC Trainer initialization\n",
    "trainer = PAVC_Trainer(args, \n",
    "                  optimizer, \n",
    "                  lr_scheduler, \n",
    "                  loss_fn,\n",
    "                 device=args['device'],\n",
    "                 model_name='DeepPAVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train DeepPAVC model\n",
    "performance_res_df = trainer.fit(model=DeepPAVC,\n",
    "                      train_loader=train_loader,\n",
    "                      val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KPGT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
