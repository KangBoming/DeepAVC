{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First training stage:  Train CADTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from utils.Func import extract_esm_feature,seq2fasta,extract_cp_feature,filter_invalid_smiles\n",
    "from dgl.data.utils import load_graphs\n",
    "from utils.TAVC_dataset import TAVC_Dataset_Train\n",
    "from utils.collator import Collator_TAVC_Train\n",
    "from utils.TAVC_trainer import TAVC_Trainer\n",
    "from utils.scheduler import PolynomialDecayLR\n",
    "from torch.optim import Adam\n",
    "from torch.nn import  BCEWithLogitsLoss\n",
    "from utils.model.KPGT_v2 import *\n",
    "from utils.model.DeepAVC import *\n",
    "from utils.featurizer import Vocab, N_ATOM_TYPES, N_BOND_TYPES,VIRTUAL_ATOM_FEATURE_PLACEHOLDER, VIRTUAL_BOND_FEATURE_PLACEHOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'config':'base',\n",
    "    'd_fps': 512,\n",
    "    'd_mds': 200,\n",
    "    'dropout':0,\n",
    "    'weight_decay':1e-6,\n",
    "    'n_tasks':1,\n",
    "    'lr': 1e-4,\n",
    "    'kpgt_model_path':'../pretrained_model/KPGT/KPGT.pth',\n",
    "    'cp_feature_dir': '../data/DeepTAVC/CPI_dataset/demo/cp_feature',\n",
    "    'pro_feature_dir': '../data/DeepTAVC/CPI_dataset/demo/pro_feature',\n",
    "    'CADTI_model_path': '../pretrained_model/DeepAVC/CADTI.pt',\n",
    "    'n_epochs':20, \n",
    "    'device':'cuda:0',\n",
    "    'random_seed': 42,\n",
    "    'batch_size':32,\n",
    "    'train_ratio': 0.8,\n",
    "    'val_ratio': 0.1,\n",
    "    'test_ratio':0.1,\n",
    "    'MLP_layer_num':2,\n",
    "    'MLP_hidden_dim':256}\n",
    "vocab = Vocab(N_ATOM_TYPES, N_BOND_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CPI dataset\n",
    "CPI_dataset = pd.read_pickle('../data/T_AVC/cpi_data/cpi_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract compound initial feature by RDKit(if necessary)\n",
    "smiles_list = CPI_dataset['SMILES'].to_list()\n",
    "# filter compound with invalid smiles \n",
    "valid_smiles, invalid_smiles = filter_invalid_smiles(smiles_list)\n",
    "extract_cp_feature(smiles_list = valid_smiles, \n",
    "                   output_dir = args['cp_feature_dir'],\n",
    "                   num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract protein initial feature by ESM-2 (if necessary)\n",
    "pro_seq_list = list(CPI_dataset['sequence'].unique())\n",
    "# Transform protein sequences into the fasta format\n",
    "seq2fasta(seq_list=pro_seq_list, \n",
    "          save_dir=args['pro_feature_dir'])\n",
    "\n",
    "extract_esm_feature(\n",
    "    model_location = '../pretrained_model/ESM/esm2_t33_650M_UR50D.pt',\n",
    "    fasta_file = os.path.join(args['pro_feature_dir'], 'target_seq.fasta'),\n",
    "    output_dir = args['pro_feature_dir'],\n",
    "    toks_per_batch = 10000,\n",
    "    repr_layers = [-1],\n",
    "    include=['per_tok'],\n",
    "    device='cuda:0',\n",
    "    truncation_seq_length = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_id_list = [ f'Target_{i+1}' for i in range(len(CPI_dataset['sequence'].unique()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2id_dict = dict(zip( CPI_dataset['sequence'].unique(),target_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPI_dataset['target_idx'] = CPI_dataset['sequence'].map(seq2id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load compound initial feature\n",
    "graphs, label_dict = load_graphs(os.path.join(args['cp_feature_dir'], 'cp_graphs.pkl'))\n",
    "fps = torch.load(os.path.join(args['cp_feature_dir'], 'cp_fps.pt'))\n",
    "mds = torch.load(os.path.join(args['cp_feature_dir'], 'cp_mds.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(graphs) == len(fps) == len(mds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load protein initial feature\n",
    "pro_feature_dict = torch.load(os.path.join(args['pro_feature_dir'],'esm_feature.pt'),map_location=args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataset\n",
    "CPI_dataset = TAVC_Dataset_Train(smiles_list = CPI_dataset['SMILES'].to_list(),\n",
    "                          target_seq_list=CPI_dataset['target_idx'].to_list(),\n",
    "                          target_feature_dict=pro_feature_dict,\n",
    "                          label_list=CPI_dataset['label'].to_list(),\n",
    "                          graphs=graphs,\n",
    "                          fps=fps,\n",
    "                          mds=mds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data split\n",
    "train_ratio = args['train_ratio']\n",
    "val_ratio = args['val_ratio']\n",
    "dataset_size = len(CPI_dataset)\n",
    "train_size = int(train_ratio * dataset_size) \n",
    "val_size = int(val_ratio * dataset_size)   \n",
    "test_size = dataset_size - train_size - val_size \n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset = random_split(CPI_dataset, [train_size, val_size, test_size])\n",
    "print(f'Train size:{len(train_dataset)}\\nValidation size:{len(val_dataset)}\\nTest size:{len(test_dataset)}')\n",
    "\n",
    "### build dataloader \n",
    "config = config_dict[args['config']]\n",
    "collator = Collator_TAVC_Train(config['path_length'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=args['batch_size'], \n",
    "                          shuffle=True,  \n",
    "                          drop_last=False, \n",
    "                          collate_fn=collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args['batch_size'], \n",
    "                        shuffle=False,\n",
    "                          drop_last=False, \n",
    "                          collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args['batch_size'], \n",
    "                         shuffle=False,  \n",
    "                         drop_last=False, \n",
    "                         collate_fn=collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpgt_model = LiGhTPredictor(\n",
    "    d_node_feats=config['d_node_feats'],\n",
    "    d_edge_feats=config['d_edge_feats'],\n",
    "    d_g_feats=config['d_g_feats'],\n",
    "    d_fp_feats=args['d_fps'],\n",
    "    d_md_feats=args['d_mds'],\n",
    "    d_hpath_ratio=config['d_hpath_ratio'],\n",
    "    n_mol_layers=config['n_mol_layers'],\n",
    "    path_length=config['path_length'],\n",
    "    n_heads=config['n_heads'],\n",
    "    n_ffn_dense_layers=config['n_ffn_dense_layers'],\n",
    "    input_drop=0,\n",
    "    attn_drop=args['dropout'],\n",
    "    feat_drop=args['dropout'],\n",
    "    n_node_types=vocab.vocab_size).to(args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained weigths of KPGT model\n",
    "kpgt_model.load_state_dict({k.replace('module.',''):v for k,v in torch.load(args['kpgt_model_path'],map_location=args['device']).items()})\n",
    "# Delete unused structure\n",
    "del kpgt_model.md_predictor\n",
    "del kpgt_model.fp_predictor\n",
    "del kpgt_model.node_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Initialization\n",
    "CADTI_model = CADTI_Finetune(\n",
    "d_model=256,\n",
    "n_heads=8,\n",
    "num_layers=1,\n",
    "kpgt_model=kpgt_model,\n",
    "smiles_dim=768,\n",
    "protein_dim=1280,\n",
    "kpgt_features_dim=2304,\n",
    "mlp_hidden_dim=256,\n",
    "num_classes=1,\n",
    "dropout=0,\n",
    "return_attn=True).to(args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model have {}M parameters in total that require gradients\".format(\n",
    "sum(p.numel() for p in CADTI_model.parameters() if p.requires_grad) / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(CADTI_model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "lr_scheduler = PolynomialDecayLR(optimizer, \n",
    "                                warmup_updates=args['n_epochs']*(len(train_loader))//100, \n",
    "                                tot_updates=args['n_epochs']*len(train_loader),\n",
    "                                lr=args['lr'], \n",
    "                                end_lr=1e-5, \n",
    "                                power=1)\n",
    "\n",
    "loss_fn = BCEWithLogitsLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TAVC_Trainer(args=args, \n",
    "                        optimizer=optimizer,\n",
    "                    lr_scheduler=lr_scheduler,\n",
    "                    loss_fn=loss_fn,\n",
    "                    device=args['device'],\n",
    "                    model_name='CADTI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_res_df = trainer.fit(model=CADTI_model,\n",
    "                    train_loader=train_loader,\n",
    "                    val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second training stage: Train DeepTAVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'config':'base',\n",
    "    'd_fps': 512,\n",
    "    'd_mds': 200,\n",
    "    'dropout':0,\n",
    "    'weight_decay':1e-6,\n",
    "    'n_tasks':1,\n",
    "    'lr': 1e-4,\n",
    "    'kpgt_model_path':'../pretrained_model/KPGT/KPGT.pth',\n",
    "    'cp_feature_dir': '../data/DeepTAVC/TAVC_dataset/cp_feature',\n",
    "    'pro_feature_dir': '../data/DeepTAVC/TAVC_dataset/pro_feature',\n",
    "    'n_epochs':20, \n",
    "    'device':'cuda:3',\n",
    "    'random_seed': 42,\n",
    "    'batch_size':32,\n",
    "    'train_ratio': 0.8,\n",
    "    'val_ratio': 0.1,\n",
    "    'test_ratio':0.1,\n",
    "    'MLP_layer_num':2,\n",
    "    'MLP_hidden_dim':256}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAVC_data = pd.read_csv('../data/DeepTAVC/TAVC_dataset/DeepTAVC_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract compound initial feature by RDKit(if necessary)\n",
    "smiles_list = TAVC_data['canonical_smiles'].to_list()\n",
    "# filter compound with invalid smiles \n",
    "valid_smiles, invalid_smiles = filter_invalid_smiles(smiles_list)\n",
    "extract_cp_feature(smiles_list = valid_smiles, \n",
    "                   output_dir = args['cp_feature_dir'],\n",
    "                   num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract protein initial feature by ESM-2 (if necessary)\n",
    "pro_seq_list = list(TAVC_data['sequence'].unique())\n",
    "# Transform protein sequences into the fasta format\n",
    "seq2fasta(seq_list=pro_seq_list, \n",
    "          save_dir=args['pro_feature_dir'])\n",
    "\n",
    "extract_esm_feature(\n",
    "    model_location = '../pretrained_model/ESM/esm2_t33_650M_UR50D.pt',\n",
    "    fasta_file = os.path.join(args['pro_feature_dir'], 'target_seq.fasta'),\n",
    "    output_dir = args['pro_feature_dir'],\n",
    "    toks_per_batch = 10000,\n",
    "    repr_layers = [-1],\n",
    "    include=['per_tok'],\n",
    "    device='cuda:3',\n",
    "    truncation_seq_length = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_id_list = [ f'Target_{i+1}' for i in range(len(TAVC_data['sequence'].unique()))]\n",
    "seq2id_dict = dict(zip( TAVC_data['sequence'].unique(),target_id_list))\n",
    "TAVC_data['target_idx'] = TAVC_data['sequence'].map(seq2id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load compound initial feature\n",
    "graphs, label_dict = load_graphs(os.path.join(args['cp_feature_dir'], 'cp_graphs.pkl'))\n",
    "fps = torch.load(os.path.join(args['cp_feature_dir'], 'cp_fps.pt'))\n",
    "mds = torch.load(os.path.join(args['cp_feature_dir'], 'cp_mds.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(graphs) == len(fps) == len(mds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load protein initial feature\n",
    "pro_feature_dict = torch.load(os.path.join(args['pro_feature_dir'],'esm_feature.pt'),map_location=args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataset\n",
    "TAVC_dataset = TAVC_Dataset_Train(smiles_list = TAVC_data['canonical_smiles'].to_list(),\n",
    "                          target_seq_list=TAVC_data['target_idx'].to_list(),\n",
    "                          target_feature_dict=pro_feature_dict,\n",
    "                          label_list=TAVC_data['avd_label'].to_list(),\n",
    "                          graphs=graphs,\n",
    "                          fps=fps,\n",
    "                          mds=mds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data split\n",
    "train_ratio = args['train_ratio']\n",
    "val_ratio = args['val_ratio']\n",
    "dataset_size = len(TAVC_dataset)\n",
    "train_size = int(train_ratio * dataset_size) \n",
    "val_size = int(val_ratio * dataset_size)   \n",
    "test_size = dataset_size - train_size - val_size \n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset = random_split(TAVC_dataset, [train_size, val_size, test_size])\n",
    "print(f'Train size:{len(train_dataset)}\\nValidation size:{len(val_dataset)}\\nTest size:{len(test_dataset)}')\n",
    "\n",
    "### build dataloader \n",
    "config = config_dict[args['config']]\n",
    "collator = Collator_TAVC_Train(config['path_length'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=args['batch_size'], \n",
    "                          shuffle=True,  \n",
    "                          drop_last=False, \n",
    "                          collate_fn=collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args['batch_size'], \n",
    "                        shuffle=False,\n",
    "                          drop_last=False, \n",
    "                          collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args['batch_size'], \n",
    "                         shuffle=False,  \n",
    "                         drop_last=False, \n",
    "                         collate_fn=collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Initialization\n",
    "DeepTAVC = CADTI_Finetune(\n",
    "d_model=256,\n",
    "n_heads=8,\n",
    "num_layers=1,\n",
    "kpgt_model=kpgt_model,\n",
    "smiles_dim=768,\n",
    "protein_dim=1280,\n",
    "kpgt_features_dim=2304,\n",
    "mlp_hidden_dim=256,\n",
    "num_classes=1,\n",
    "dropout=0,\n",
    "return_attn=True).to(args['device'])\n",
    "print(\"model have {}M parameters in total that require gradients\".format(\n",
    "sum(p.numel() for p in DeepTAVC.parameters() if p.requires_grad) / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepTAVC.load_state_dict(torch.load(args['CADTI_model_path'],map_location=args['device'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TAVC_Trainer(args=args, \n",
    "                        optimizer=optimizer,\n",
    "                    lr_scheduler=lr_scheduler,\n",
    "                    loss_fn=loss_fn,\n",
    "                    device=args['device'],\n",
    "                    model_name='DeepTAVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_res_df = trainer.fit(model=DeepTAVC,\n",
    "                    train_loader=train_loader,\n",
    "                    val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KPGT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
